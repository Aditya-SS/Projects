# -*- coding: utf-8 -*-
"""Titanic_Data_preprocessing_SVM.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1T-6ljZz9lfUCY0RjgxFk-EtBaoKG7mRi
"""

import pandas as pd
import numpy as np

from google.colab import files
  
uploaded = files.upload()

train = pd.read_csv("train.csv")
test = pd.read_csv("test.csv")

for i in train.columns:
    print (i + ": "+str(sum(train[i].isnull()))+" missing values")

for i in test.columns:
    print (i + ": "+str(sum(test[i].isnull()))+" missing values")

train_1=train.groupby(["Pclass","SibSp"])
train_1_median=train_1.median()
train_1_median

test_1=test.groupby(["Pclass","SibSp"])
test_1_median=test_1.median()
test_1_median

def fill_train_age(dataset,dataset_med):
    for x in range(len(dataset)):
        if dataset["Pclass"][x]==1:
            if dataset["SibSp"][x]==0:
                return dataset_med.loc[1,0]["Age"]
            elif dataset["SibSp"][x]==1:
                return dataset_med.loc[1,1]["Age"]
            elif dataset["SibSp"][x]==2:
                return dataset_med.loc[1,2]["Age"]
            elif dataset["SibSp"][x]==3:
                return dataset_med.loc[1,3]["Age"]
        elif dataset["Pclass"][x]==2:
            if dataset["SibSp"][x]==0:
                return dataset_med.loc[2,0]["Age"]
            elif dataset["SibSp"][x]==1:
                return dataset_med.loc[2,1]["Age"]
            elif dataset["SibSp"][x]==2:
                return dataset_med.loc[2,2]["Age"]
            elif dataset["SibSp"][x]==3:
                return dataset_med.loc[2,3]["Age"]
        elif dataset["Pclass"][x]==3:
            if dataset["SibSp"][x]==0:
                return dataset_med.loc[3,0]["Age"]
            elif dataset["SibSp"][x]==1:
                return dataset_med.loc[3,1]["Age"]
            elif dataset["SibSp"][x]==2:
                return dataset_med.loc[3,2]["Age"]
            elif dataset["SibSp"][x]==3:
                return dataset_med.loc[3,3]["Age"]
            elif dataset["SibSp"][x]==4:
                return dataset_med.loc[3,4]["Age"]
            elif dataset["SibSp"][x]==5:
                return dataset_med.loc[3,5]["Age"]
            elif dataset["SibSp"][x]==8:
                return dataset_med.loc[3]["Age"].median()

train["Age"]=train["Age"].fillna(fill_train_age(train,train_1_median))

def fill_test_age(dataset,dataset_med):
    for x in range(len(dataset)):
        if dataset["Pclass"][x]==1:
            if dataset["SibSp"][x]==0:
                return dataset_med.loc[1,0]["Age"]
            elif dataset["SibSp"][x]==1:
                return dataset_med.loc[1,1]["Age"]
            elif dataset["SibSp"][x]==2:
                return dataset_med.loc[1,2]["Age"]
            elif dataset["SibSp"][x]==3:
                return dataset_med.loc[1,3]["Age"]
        elif dataset["Pclass"][x]==2:
            if dataset["SibSp"][x]==0:
                return dataset_med.loc[2,0]["Age"]
            elif dataset["SibSp"][x]==1:
                return dataset_med.loc[2,1]["Age"]
            elif dataset["SibSp"][x]==2:
                return dataset_med.loc[2,2]["Age"]
            elif dataset["SibSp"][x]==3:
                return dataset_med.loc[2,3]["Age"]
        elif dataset["Pclass"][x]==3:
            if dataset["SibSp"][x]==0:
                return dataset_med.loc[3,0]["Age"]
            elif dataset["SibSp"][x]==1:
                return dataset_med.loc[3,1]["Age"]
            elif dataset["SibSp"][x]==2:
                return dataset_med.loc[3,2]["Age"]
            elif dataset["SibSp"][x]==3:
                return dataset_med.loc[3,3]["Age"]
            elif dataset["SibSp"][x]==4:
                return dataset_med.loc[3,4]["Age"]
            elif dataset["SibSp"][x]==5:
                return dataset_med.loc[3,5]["Age"]
            elif dataset["SibSp"][x]==8:
                return dataset_med.loc[3,8]["Age"]

test["Age"]=test["Age"].fillna(fill_test_age(test,test_1_median))

train.Cabin.unique()

train["Cabin"]=train["Cabin"].fillna("U")
train["Cabin"]=train["Cabin"].map(lambda x: x[0])

train.Cabin.unique()

test.Cabin.unique()

test["Cabin"]=test["Cabin"].fillna("U")
test["Cabin"]=test["Cabin"].map(lambda x: x[0])

test.Cabin.unique()

train.Embarked.value_counts()

train["Embarked"]=train["Embarked"].fillna("S")

test["Fare"]=test["Fare"].fillna(test["Fare"].mean())

train = train.drop(["Name"],axis=1)
train = train.drop(["Ticket"],axis=1)
test = test.drop(["Name"],axis=1)
test = test.drop(["Ticket"],axis=1)

import seaborn as sns

plt.title("Survival rate based on fare and age")
sns.scatterplot(x=train.Age, y=train.Fare, hue=train.Survived, s=100);

import warnings
warnings.filterwarnings("ignore")

import matplotlib.pyplot as plt

Cabin_list = np.unique(train['Cabin'])
y=[]
for cabin in Cabin_list:
  y.append((len(train[train.Cabin==cabin][train.Survived==True])/len(train[train.Cabin==cabin]))*100)
plt.title("Survival rate based on Cabin")
plt.xlabel("Cabin")
plt.ylabel("Survival percentage")
plt.bar(Cabin_list,y)

Sex_list = np.unique(train['Sex'])
z=[]
for sex in Sex_list:
  z.append((len(train[train.Sex==sex][train.Survived==True])/len(train[train.Sex==sex]))*100)
plt.title("Survival rate based on Sex")
plt.xlabel("Sex")
plt.ylabel("Survival percentage")
plt.bar(Sex_list,z)

from sklearn import preprocessing

le = preprocessing.LabelEncoder()

le.fit(train["Sex"])
le.classes_
train["Sex"] = le.transform(train["Sex"])
test["Sex"] = le.transform(test["Sex"])

le1 = preprocessing.LabelEncoder()

le1.fit(train["Embarked"])
le1.classes_
train["Embarked"] = le1.transform(train["Embarked"])
test["Embarked"] = le1.transform(test["Embarked"])

le2 = preprocessing.LabelEncoder()

le2.fit(train["Cabin"])
le2.classes_
train["Cabin"] = le2.transform(train["Cabin"])
test["Cabin"] = le2.transform(test["Cabin"])

train.head()

x_train = train.drop(["Survived"],axis=1)
y_train = train["Survived"]

from sklearn.preprocessing import StandardScaler

x = StandardScaler().fit_transform(x_train)

print(x)

from sklearn.decomposition import PCA
pca = PCA(n_components=2)
principalComponents = pca.fit_transform(x)
principalDf = pd.DataFrame(data = principalComponents
             , columns = ['principal_component_1', 'principal_component_2'])

principalDf.head()

finalDf = pd.concat([principalDf, y_train], axis = 1)

finalDf.head()

import seaborn as sns

sns.scatterplot(x=finalDf.principal_component_1, y=finalDf.principal_component_2, hue=finalDf.Survived, s=100);

from sklearn.svm import SVC

x_train.head()

test.head()

y_train.head()

from sklearn.model_selection import GridSearchCV
  
param_grid = {'C': [0.1, 1, 10, 100, 1000],
              'kernel': ['linear']} 
  
grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3, cv=5)
  
grid.fit(x_train, y_train)
grid.score(x_train, y_train)

grid.best_params_

from sklearn.model_selection import GridSearchCV
  
param_grid = {'C': [0.01,0.05,0.1,0.5,1],
              'kernel': ['linear']} 
  
grid1 = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3, cv=5)
  
grid1.fit(x_train, y_train)
grid1.score(x_train, y_train)

grid1.best_params_

from sklearn.model_selection import GridSearchCV

param_grid = {'C': [0.01, 0.1, 1, 10, 100],
              'gamma':[0.01,0.1,1,10,100],
              'kernel': ['rbf']} 
  
grid2 = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3, cv=5)
  
grid2.fit(x_train, y_train)
grid2.score(x_train, y_train)

grid2.best_params_

a1=grid1.best_estimator_.predict(test)
a1df = pd.DataFrame(data=a1)
a1df.to_csv("Linear_predictions.csv",index=False)

a2=grid2.best_estimator_.predict(test)
a2df = pd.DataFrame(data=a2)
a2df.to_csv("RBF_predictions.csv",index=False)

from google.colab import files

files.download("Linear_predictions.csv")
files.download("RBF_predictions.csv")